{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Complete Evaluation Table and aggregate the Absolute Errors by Mean --> generating MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# We concatenate the evaluation results of the quantifiers and the ensemble quantifier\n",
    "# to have a single table for the evaluation results\n",
    "\n",
    "# EXPERIMENT 1\n",
    "# Meta-features extraidas de full set, sem normalização\n",
    "# Quantificadores treinados em train set, com zscore\n",
    "# Quantificadores avaliados em test set, com zscore\n",
    "\n",
    "# EXPERIMENT 2\n",
    "# Meta-features extraidas de train set, com zscore\n",
    "# Quantificadores treinados em train set, com zscore\n",
    "# Quantificadores avaliados em test set, com zscore\n",
    "\n",
    "# EXPERIMENT 3 (AINDA NÃO FEITO)\n",
    "# Meta-features extraidas de train set, sem normalização\n",
    "# Quantificadores treinados em train set, com zscore\n",
    "# Quantificadores avaliados em test set, com zscore\n",
    "\n",
    "path = \"./plot_data/experiment-1/\"\n",
    "\n",
    "# path = \"./plot_data/\"\n",
    "\n",
    "quantifiers_eval = pd.read_csv(path+\"reg_quantifiers_evaluation_table.csv\")\n",
    "\n",
    "# reg_ensemble_quantifier_eval = pd.read_csv(path+\"reg_ensemble_quantifier_evaluation_table.csv\")\n",
    "\n",
    "reg_ensemble_quantifier_eval = pd.read_csv(path+\"results/neigh_reg/reg_ensemble_quantifier_evaluation_table_KNN.csv\")\n",
    "# reg_ensemble_quantifier_eval = pd.read_csv(path+\"results/neigh_reg/reg_ensemble_quantifier_evaluation_table_KNN_GRID.csv\")\n",
    "\n",
    "\n",
    "# reg_ensemble_quantifier_eval = pd.read_csv(path+\"results/rf_reg/reg_ensemble_quantifier_evaluation_table_RF.csv\")\n",
    "\n",
    "# reg_ensemble_quantifier_eval = pd.read_csv(path+\"results/svr_reg/reg_ensemble_quantifier_evaluation_table_SVR.csv\")\n",
    "# reg_ensemble_quantifier_eval = pd.read_csv(path+\"results/svr_reg/reg_ensemble_quantifier_evaluation_table_SVR_GRID_1.csv\")\n",
    "# reg_ensemble_quantifier_eval = pd.read_csv(path+\"results/svr_reg/reg_ensemble_quantifier_evaluation_table_SVR_GRID_2.csv\")\n",
    "\n",
    "# reg_ensemble_quantifier_eval = pd.read_csv(path+\"results/xgbr_reg/reg_ensemble_quantifier_evaluation_table_XGBR.csv\")\n",
    "\n",
    "knn_ensemble_quantifier_eval = pd.read_csv(path+\"knn_ensemble_quantifier_evaluation_table.csv\")\n",
    "eval_table = pd.concat([quantifiers_eval, reg_ensemble_quantifier_eval, knn_ensemble_quantifier_eval], axis=0)\n",
    "\n",
    "\n",
    "eval_table = eval_table.groupby([\"quantifier\", \"dataset\"]).agg(\n",
    "        abs_error = pd.NamedAgg(column=\"abs_error\", aggfunc=\"mean\"),\n",
    "        run_time = pd.NamedAgg(column=\"run_time\", aggfunc=\"mean\")\n",
    "    )\n",
    "eval_table.reset_index(inplace=True)\n",
    "\n",
    "def remove_quantifiers(df, quantifiers):\n",
    "    return df[~df['quantifier'].isin(quantifiers)]\n",
    "\n",
    "quantifiers_to_remove = [\n",
    "    '(KNN)Top-1',\n",
    "    '(KNN)Top-2',\n",
    "    '(KNN)Top-3',\n",
    "    '(KNN)Top-4',\n",
    "    '(KNN)Top-5',\n",
    "    '(KNN)Top-6',\n",
    "    '(KNN)Top-7',\n",
    "    '(KNN)Top-8',\n",
    "    '(KNN)Top-9',\n",
    "    '(KNN)Top-10',\n",
    "    '(KNN)Top-11',\n",
    "    '(KNN)Top-1+W',\n",
    "    '(KNN)Top-2+W',\n",
    "    '(KNN)Top-3+W',\n",
    "    '(KNN)Top-4+W',\n",
    "    '(KNN)Top-5+W',\n",
    "    '(KNN)Top-6+W',\n",
    "    '(KNN)Top-7+W',\n",
    "    '(KNN)Top-8+W',\n",
    "    '(KNN)Top-9+W',\n",
    "    '(KNN)Top-10+W',\n",
    "    '(KNN)Top-11+W',\n",
    "    # '(REG)Top-1',\n",
    "    '(REG)Top-2',\n",
    "    '(REG)Top-3',\n",
    "    '(REG)Top-4',\n",
    "    '(REG)Top-5',\n",
    "    '(REG)Top-6',\n",
    "    '(REG)Top-7',\n",
    "    '(REG)Top-8',\n",
    "    '(REG)Top-9',\n",
    "    '(REG)Top-10',\n",
    "    '(REG)Top-11',\n",
    "    '(REG)Top-1+W',\n",
    "    '(REG)Top-2+W',\n",
    "    '(REG)Top-3+W',\n",
    "    '(REG)Top-4+W',\n",
    "    '(REG)Top-5+W',\n",
    "    '(REG)Top-6+W',\n",
    "    '(REG)Top-7+W',\n",
    "    '(REG)Top-8+W',\n",
    "    '(REG)Top-9+W',\n",
    "    '(REG)Top-10+W',\n",
    "    '(REG)Top-11+W',\n",
    "]\n",
    "eval_table = remove_quantifiers(eval_table, quantifiers_to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Ranking Plots by Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "margin_left = 0.05\n",
    "margin_right= 0.99\n",
    "margin_top = 0.99\n",
    "margin_bottom = .24 # .23\n",
    "plt_width = 52 # 38\n",
    "plt_heigth = 24 # 18\n",
    "plot_rotation = 75\n",
    "axis_font_size = 56 # 50\n",
    "labels_size = 60 # 60\n",
    "\n",
    "def boxplotMae(sample, file=\"\"):\n",
    "    sample['error_rank'] = sample.groupby(['dataset'], as_index=False )['abs_error'].rank(method='average', ascending = True)\n",
    "\n",
    "    order = sample.groupby('quantifier')['error_rank'].mean().sort_values().index\n",
    "\n",
    "    palette = sns.color_palette('Spectral', sample['quantifier'].nunique())\n",
    "\n",
    "    with sns.axes_style(\"whitegrid\"):\n",
    "        plt.figure(figsize=(plt_width, plt_heigth))\n",
    "        plt.subplots_adjust(left=margin_left, bottom=margin_bottom, right=margin_right, top=margin_top)\n",
    "        ax=sns.boxplot(data=sample, x='quantifier', y='error_rank', order = order, palette = palette, hue='quantifier', legend=False)\n",
    "\n",
    "        plt.xticks(rotation =plot_rotation ,fontsize = axis_font_size)\n",
    "        plt.yticks(fontsize = axis_font_size)\n",
    "\n",
    "        ax.set_xlabel(\"Quantifiers\",fontsize=labels_size)\n",
    "        ax.set_ylabel(\"Avg. ranking\",fontsize=labels_size)\n",
    "\n",
    "    plt.show()\n",
    "    # if file != \"\":\n",
    "    #     ax.figure.savefig('./figs/'+file+ '.pdf', format=\"pdf\", facecolor='w')\n",
    "\n",
    "    return sample\n",
    "\n",
    "boxplotMae(eval_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.metrics import r2_score\n",
    "\n",
    "# path = \"./plot_data/experiment-1/\"\n",
    "\n",
    "\n",
    "# reg_ensemble_quantifier_eval = pd.read_csv(path+\"reg_recommender_evaluation_table.csv\", index_col=0)\n",
    "# knn_ensemble_quantifier_eval = pd.read_csv(path+\"knn_recommender_evaluation_table.csv\", index_col=0)\n",
    "\n",
    "\n",
    "\n",
    "# qtf_list = reg_ensemble_quantifier_eval['predicted_ranking'].apply(eval).iloc[0]\n",
    "# qtf_dict = {qtf: {\"predicted\": [], \"true\": []} for qtf in qtf_list}\n",
    "\n",
    "\n",
    "\n",
    "# reg_ensemble_quantifier_eval['predicted_ranking'] = reg_ensemble_quantifier_eval['predicted_ranking'].apply(eval)\n",
    "# reg_ensemble_quantifier_eval['true_ranking'] = reg_ensemble_quantifier_eval['true_ranking'].apply(eval)\n",
    "# reg_ensemble_quantifier_eval['predicted_ranking_mae'] = reg_ensemble_quantifier_eval['predicted_ranking_mae'].apply(eval)\n",
    "# reg_ensemble_quantifier_eval['true_ranking_mae'] = reg_ensemble_quantifier_eval['true_ranking_mae'].apply(eval)\n",
    "\n",
    "# knn_ensemble_quantifier_eval['predicted_ranking'] = knn_ensemble_quantifier_eval['predicted_ranking'].apply(eval)\n",
    "# knn_ensemble_quantifier_eval['true_ranking'] = knn_ensemble_quantifier_eval['true_ranking'].apply(eval)\n",
    "# knn_ensemble_quantifier_eval['predicted_ranking_arr'] = knn_ensemble_quantifier_eval['predicted_ranking_arr'].apply(eval)\n",
    "# knn_ensemble_quantifier_eval['true_ranking_arr'] = knn_ensemble_quantifier_eval['true_ranking_arr'].apply(eval)\n",
    "\n",
    "# for i in range(len(reg_ensemble_quantifier_eval)):\n",
    "#     row = reg_ensemble_quantifier_eval.iloc[i]\n",
    "\n",
    "#     predicted_ranking = row['predicted_ranking']\n",
    "#     predicted_ranking_mae = row['predicted_ranking_mae']\n",
    "#     true_ranking = row['true_ranking']\n",
    "#     true_ranking_mae = row['true_ranking_mae']\n",
    "\n",
    "#     for qtf, mae in zip(predicted_ranking, predicted_ranking_mae):\n",
    "#         qtf_dict[qtf]['predicted'].append(mae)\n",
    "\n",
    "#     for qtf, mae in zip(true_ranking, true_ranking_mae):\n",
    "#         qtf_dict[qtf]['true'].append(mae)\n",
    "\n",
    "# for key, value in qtf_dict.items():\n",
    "#     quantifier = key\n",
    "#     predicted_ranking_mae = value['predicted']\n",
    "#     true_ranking_mae = value['true']\n",
    "\n",
    "#     r2 = r2_score(true_ranking_mae, predicted_ranking_mae)\n",
    "#     print(f\"R^2 value for {quantifier}: {r2}\")\n",
    "\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.scatter(true_ranking_mae, predicted_ranking_mae, color='blue')\n",
    "#     plt.plot([min(true_ranking_mae), max(true_ranking_mae)], [min(true_ranking_mae), max(true_ranking_mae)], color='red', linestyle='--')\n",
    "#     plt.xlabel('True Ranking MAE', fontsize=16)\n",
    "#     plt.ylabel('Predicted Ranking MAE', fontsize=16)\n",
    "#     plt.title(f'R^2 value for {quantifier} Recommender: {r2}', fontsize=16)\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
